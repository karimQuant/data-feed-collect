apiVersion: batch/v1
kind: CronJob
metadata:
  name: data-feed-collect-cronjob
spec:
  schedule: "*/30 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          imagePullSecrets:
            - name: ghcr-secret
          containers:
          - name: collector
            image: ghcr.io/karimquant/data-feed-collect:latest
            imagePullPolicy: IfNotPresent # Or Always, depending on your update strategy

            env:
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: postgres-db
            - name: DATABASE_URL
              value: "postgresql+psycopg2://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres-service:5432/$(POSTGRES_DB)"

            # Add resource requests/limits here if needed
            # resources:
            #   requests:
            #     memory: "64Mi"
            #     cpu: "250m"
            #   limits:
            #     memory: "128Mi"
            #     cpu: "500m"
            # Add command/args if your container needs specific entrypoint overrides
            # command: ["python", "data_feed_collect/main.py"] # Example
            # args: ["--some-arg", "some-value"] # Example
          restartPolicy: OnFailure # Restart the container if it fails
  # Optional: Configure concurrency policy, suspend, successfulJobsHistoryLimit, failedJobsHistoryLimit
  # concurrencyPolicy: Allow # Allow multiple job instances to run concurrently (default)
  # successfulJobsHistoryLimit: 3 # Keep the last 3 successful jobs
  # failedJobsHistoryLimit: 1 # Keep the last 1 failed job
